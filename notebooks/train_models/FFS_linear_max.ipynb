{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import glob, os, gc\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Add the path to the directory containing the module\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from util.ml import baseline, metrics, nestedMLR\n",
    "\n",
    "from properscoring import crps_ensemble  # For CRPS calculation\n",
    "from sklearn.utils import resample  # For bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the folder name organized by seed number\n",
    "seed_doc = sorted(glob.glob('../../datas/seed_revised_*/'))[0]\n",
    "\n",
    "# Load the data\n",
    "# Load the time series data\n",
    "df = pd.read_csv(seed_doc +'X_train_ts_all.csv')\n",
    "df_valid = pd.read_csv(seed_doc +'X_validation_ts_all.csv')\n",
    "df_test = pd.read_csv(seed_doc +'X_test_ts_all.csv')\n",
    "# Find the name for each column\n",
    "column_names = ([obj.split('_step_')[0] for obj in df.columns])\n",
    "# Unique names in the column name list\n",
    "unique_names = list(set(column_names))\n",
    "unique_names_filt = [obj for obj in unique_names if 'large_scale' not in obj]\n",
    "\n",
    "pcs_train = baseline.load_pickle(f'../../datas/proc/sfs/pcsall_train.pkl')\n",
    "pcs_val = baseline.load_pickle(f'../../datas/proc/sfs/pcsall_valid.pkl')\n",
    "\n",
    "# Now we read in the y data for every fold\n",
    "y_train = []\n",
    "y_val = []\n",
    "for i in range(7):\n",
    "    y_train.append(baseline.load_pickle(f'../../datas/proc/sfs/y/ytrain_split_{i}.pkl'))\n",
    "    y_val.append(baseline.load_pickle(f'../../datas/proc/sfs/y/yval_split_{i}.pkl'))\n",
    "\n",
    "# Load the test data\n",
    "y_test = baseline.load_pickle('../../datas/proc/sfs/y/ytest.pkl')\n",
    "y_testz = [y_test for i in range(7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tqdm import tqdm\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of variable names\n",
    "var_names = list(pcs_train[0].keys())\n",
    "\n",
    "# Empty list to store the chosen variables\n",
    "selected_vars = []\n",
    "# List to store all the variable choices\n",
    "remaining_vars = [var for var in var_names if \"large_scale\" not in var].copy()\n",
    "# Initial RMSE to beat is infinity\n",
    "best_val_rmse = float('inf')\n",
    "# Target transformation category\n",
    "target_cat = 'max'\n",
    "# Seed\n",
    "seed = 42\n",
    "# Hyperparameter space for the random forest\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100],\n",
    "    \"max_depth\": [None],\n",
    "    \"min_samples_split\": [2],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from natsort import natsorted\n",
    "def r2_score_f(y_true,y_pred):\n",
    "    y_true = y_true.flatten()\n",
    "    y_pred = y_pred.flatten()\n",
    "\n",
    "    r2 = 1-np.sum((y_true-y_pred)**2)/np.sum((y_true-np.mean(y_true))**2)\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected PC: geopotential_500_min_PC1, Train RMSE: 5.49161205270351, Val RMSE: 5.469222314457427\n",
      "Selected PC: 100m_magnitude_of_wind_min_PC4, Train RMSE: 5.2722813353341085, Val RMSE: 5.358255958740794\n",
      "Selected PC: mean_top_net_long_wave_radiation_flux_min_PC1, Train RMSE: 5.04590101911309, Val RMSE: 5.268538471732891\n",
      "Selected PC: surface_sensible_heat_flux_max_PC1, Train RMSE: 4.877946861130859, Val RMSE: 5.172161830022704\n",
      "Selected PC: mean_vertically_integrated_moisture_divergence_std_PC5, Train RMSE: 4.6862509642980275, Val RMSE: 5.08572205520873\n",
      "Selected PC: 2m_temperature_max_PC8, Train RMSE: 4.550666728708803, Val RMSE: 4.999789528465514\n",
      "Selected PC: relative_humidity_150_min_PC3, Train RMSE: 4.3616851269015235, Val RMSE: 4.923617760012242\n",
      "Selected PC: relative_humidity_500_mean_PC9, Train RMSE: 4.184191076029865, Val RMSE: 4.855652274198742\n",
      "Selected PC: relative_humidity_400_std_PC3, Train RMSE: 4.031929940564026, Val RMSE: 4.784958899409555\n",
      "Selected PC: relative_humidity_950_min_PC10, Train RMSE: 3.9277766132987533, Val RMSE: 4.71986893845539\n",
      "Selected PC: k_index_std_PC5, Train RMSE: 3.8317099854942804, Val RMSE: 4.670826960418708\n",
      "Selected PC: surface_sensible_heat_flux_std_PC8, Train RMSE: 3.7321480529086366, Val RMSE: 4.62552992027401\n",
      "Selected PC: mean_surface_latent_heat_flux_std_PC9, Train RMSE: 3.5979309274154394, Val RMSE: 4.585693464898509\n",
      "Selected PC: mean_top_net_long_wave_radiation_flux_std_PC2, Train RMSE: 3.4600916601438985, Val RMSE: 4.524100671064138\n",
      "Selected PC: k_index_min_PC6, Train RMSE: 3.3568947002719187, Val RMSE: 4.4983398235261225\n",
      "Selected PC: relative_humidity_900_min_PC1, Train RMSE: 3.2766804918195853, Val RMSE: 4.468572811769621\n",
      "Selected PC: 10m_magnitude_of_wind_max_PC9, Train RMSE: 3.102320128225286, Val RMSE: 4.437286657027019\n",
      "Selected PC: mean_surface_sensible_heat_flux_min_PC10, Train RMSE: 3.0337500675930493, Val RMSE: 4.4021589608540115\n",
      "Selected PC: mean_vertically_integrated_moisture_divergence_mean_PC11, Train RMSE: 2.956911410780092, Val RMSE: 4.384919878118984\n",
      "Selected PC: relative_humidity_900_std_PC6, Train RMSE: 2.836664437508271, Val RMSE: 4.354354871266143\n",
      "No improvement. Stopping feature selection.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize variables\n",
    "selected_pcs = []  # List to store selected PCs\n",
    "remaining_vars = [var for var in var_names if \"large_scale\" not in var].copy()  # All variables initially available for selection\n",
    "tofilt = ['_10_', '_20_', '_30_', '_50_', '_70_']\n",
    "remaining_vars = [var for var in remaining_vars if not any(substring in var for substring in tofilt)] # Filter out specific pressure levels\n",
    "best_val_rmse = float('inf')  # Start with a very high RMSE value\n",
    "\n",
    "# Track RMSEs\n",
    "rmse_log = []  # List to log RMSE values for each iteration\n",
    "\n",
    "while remaining_vars:\n",
    "    best_var = None\n",
    "    best_pc_index = None\n",
    "    #best_iseed = None\n",
    "    best_mean_val_rmse = best_val_rmse\n",
    "    best_mean_train_rmse = None\n",
    "\n",
    "    # Test each variable\n",
    "    for var in remaining_vars:\n",
    "        nPC = pcs_train[0][var].shape[1]  # Number of PCs for this variable\n",
    "\n",
    "        # Test each PC of the variable\n",
    "        for pc_index in range(nPC):\n",
    "            train_scores = []\n",
    "            mean_score = []\n",
    "\n",
    "            # Evaluate using all seeds\n",
    "            for iseed in range(7):\n",
    "                # Prepare data for the current candidate PC\n",
    "                candidate_features = [pcs_train[iseed][sel_var][:, [pc_idx]] \n",
    "                                      for sel_var, pc_idx in selected_pcs]\n",
    "                candidate_features.append(pcs_train[iseed][var][:, [pc_index]])\n",
    "                X_train_subset = np.hstack(candidate_features)\n",
    "                X_val_subset = np.hstack(\n",
    "                    [pcs_val[iseed][sel_var][:, [pc_idx]] for sel_var, pc_idx in selected_pcs] +\n",
    "                    [pcs_val[iseed][var][:, [pc_index]]]\n",
    "                )\n",
    "\n",
    "                # Train a model and evaluate\n",
    "                model = linear_model.LinearRegression()\n",
    "                model.fit(X_train_subset, y_train[iseed][target_cat])\n",
    "                y_pred = model.predict(X_val_subset)\n",
    "\n",
    "                # Training RMSE\n",
    "                y_train_pred = model.predict(X_train_subset)\n",
    "                train_rmse = mean_squared_error(y_train[iseed][target_cat], y_train_pred, squared=False)\n",
    "                #train_rmse = -r2_score_f(y_train[iseed][target_cat], y_train_pred)\n",
    "                train_scores.append(train_rmse)\n",
    "\n",
    "                # Calculate the validation RMSE\n",
    "                val_rmse = mean_squared_error(y_val[iseed][target_cat], y_pred, squared=False)\n",
    "                #val_rmse = -r2_score_f(y_val[iseed][target_cat], y_pred)\n",
    "                mean_score.append(val_rmse)\n",
    "\n",
    "            # Compute the mean training RMSE across seeds\n",
    "            mean_train_rmse = np.mean(train_scores)\n",
    "            # Compute the mean validation RMSE across seeds\n",
    "            mean_val_rmse = np.mean(mean_score)\n",
    "\n",
    "            # Update the best PC if this one performs better\n",
    "            if mean_val_rmse < best_mean_val_rmse:\n",
    "                best_mean_val_rmse = mean_val_rmse\n",
    "                best_mean_train_rmse = mean_train_rmse\n",
    "                best_var = var\n",
    "                best_pc_index = pc_index\n",
    "                #best_iseed = current_best_iseed\n",
    "\n",
    "    # Check if we found a PC that improves validation RMSE\n",
    "    if best_var and best_mean_val_rmse < best_val_rmse:\n",
    "        # Add the best-performing PC to the selected set\n",
    "        selected_pcs.append((best_var, best_pc_index))\n",
    "        remaining_vars.remove(best_var)\n",
    "        best_val_rmse = best_mean_val_rmse\n",
    "\n",
    "        # Log RMSEs for this iteration\n",
    "        rmse_log.append({\n",
    "            \"selected_pc\": f\"{best_var}_PC{best_pc_index + 1}\",\n",
    "            \"train_rmse\": best_mean_train_rmse,\n",
    "            \"val_rmse\": best_mean_val_rmse,\n",
    "        })\n",
    "        print(f\"Selected PC: {best_var}_PC{best_pc_index + 1}, Train RMSE: {best_mean_train_rmse}, Val RMSE: {best_mean_val_rmse}\")\n",
    "    else:\n",
    "        print(\"No improvement. Stopping feature selection.\")\n",
    "        break\n",
    "\n",
    "# Train the final model using all selected PCs and all training data\n",
    "final_X_train = np.hstack(\n",
    "    [pcs_train[0][sel_var][:, [pc_idx]] for sel_var, pc_idx in selected_pcs]\n",
    ")\n",
    "final_model = linear_model.LinearRegression()\n",
    "final_model.fit(final_X_train, y_train[0][target_cat])\n",
    "\n",
    "# Save the final model\n",
    "#baseline.save_models(final_model,f'../../datas/proc/sfs/results/best_linear_max_model_r2.pkl')\n",
    "#baseline.save_models(selected_pcs,f'../../datas/proc/sfs/results/best_linear_max_feature_r2.pkl')\n",
    "#baseline.save_models(rmse_log,f'../../datas/proc/sfs/results/best_linear_max_R2log.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the final model using all selected PCs and all training data\n",
    "final_X_train = np.hstack(\n",
    "    [pcs_train[0][sel_var][:, [pc_idx]] for sel_var, pc_idx in selected_pcs]\n",
    ")\n",
    "final_model = linear_model.LinearRegression()\n",
    "final_model.fit(final_X_train, y_train[0][target_cat])\n",
    "\n",
    "# Save the final model\n",
    "baseline.save_models(final_model,f'../../datas/proc/sfs/results/best_linear_max_model.pkl')\n",
    "baseline.save_models(selected_pcs,f'../../datas/proc/sfs/results/best_linear_max_feature.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected PC: mean_surface_latent_heat_flux_std_PC8, Mean Val RMSE: 4.046519506411527, Seed: 0\n",
      "Selected PC: 10m_u_component_of_wind_std_PC4, Mean Val RMSE: 3.8527484877697766, Seed: 0\n",
      "Selected PC: surface_latent_heat_flux_mean_PC2, Mean Val RMSE: 3.753582792237446, Seed: 0\n",
      "Selected PC: mean_sea_level_pressure_max_PC9, Mean Val RMSE: 3.675957197286574, Seed: 0\n",
      "Selected PC: 10m_u_component_of_wind_max_PC7, Mean Val RMSE: 3.618071848186584, Seed: 0\n",
      "Selected PC: geopotential_500_mean_PC2, Mean Val RMSE: 3.5877797022992963, Seed: 0\n",
      "Selected PC: mean_sea_level_pressure_mean_PC4, Mean Val RMSE: 3.5406891172095594, Seed: 0\n",
      "Selected PC: surface_pressure_max_PC5, Mean Val RMSE: 3.533518653922654, Seed: 0\n",
      "Selected PC: geopotential_1000_min_PC5, Mean Val RMSE: 3.525916407559397, Seed: 0\n",
      "Selected PC: surface_latent_heat_flux_std_PC9, Mean Val RMSE: 3.4839081333258624, Seed: 0\n",
      "Selected PC: mean_sea_level_pressure_min_PC8, Mean Val RMSE: 3.458098561269266, Seed: 0\n",
      "Selected PC: geopotential_500_max_PC5, Mean Val RMSE: 3.444617205563069, Seed: 0\n",
      "No improvement. Stopping feature selection.\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables\n",
    "selected_pcs = []  # List to store selected PCs\n",
    "remaining_vars = list(pcs_train[0].keys())  # All variables initially available for selection\n",
    "best_val_crps = float('inf')  # Start with a very high RMSE value\n",
    "\n",
    "while remaining_vars:\n",
    "    best_var = None\n",
    "    best_pc_index = None\n",
    "    best_iseed = None\n",
    "    best_mean_val_crps = best_val_crps\n",
    "\n",
    "    # Test each variable\n",
    "    for var in remaining_vars:\n",
    "        nPC = pcs_train[0][var].shape[1]  # Number of PCs for this variable\n",
    "\n",
    "        # Test each PC of the variable\n",
    "        for pc_index in range(nPC):\n",
    "            mean_score = []\n",
    "\n",
    "            # Evaluate using all seeds\n",
    "            for iseed in range(7):\n",
    "                # Prepare data for the current candidate PC\n",
    "                candidate_features = [pcs_train[iseed][sel_var][:, [pc_idx]] \n",
    "                                      for sel_var, pc_idx in selected_pcs]\n",
    "                candidate_features.append(pcs_train[iseed][var][:, [pc_index]])\n",
    "                X_train_subset = np.hstack(candidate_features)\n",
    "                X_val_subset = np.hstack(\n",
    "                    [pcs_val[iseed][sel_var][:, [pc_idx]] for sel_var, pc_idx in selected_pcs] +\n",
    "                    [pcs_val[iseed][var][:, [pc_index]]]\n",
    "                )\n",
    "\n",
    "                # Train a model and evaluate\n",
    "                model = linear_model.LinearRegression()\n",
    "                model.fit(X_train_subset, y_train[iseed][target_cat])\n",
    "                y_pred = model.predict(X_val_subset)\n",
    "\n",
    "                # Generate ensemble predictions using bootstrapping\n",
    "                y_pred_ensemble = []\n",
    "                for _ in range(100):  # Number of ensemble members\n",
    "                    bootstrap_X, bootstrap_y = resample(X_train_subset, y_train[iseed][target_cat])\n",
    "                    bootstrap_model = linear_model.LinearRegression()\n",
    "                    bootstrap_model.fit(bootstrap_X, bootstrap_y)\n",
    "                    y_pred_ensemble.append(bootstrap_model.predict(X_val_subset))\n",
    "                y_pred_ensemble = np.array(y_pred_ensemble)  # Shape: (n_samples, n_ensemble)\n",
    "\n",
    "                # Calculate the CRPS score\n",
    "                val_crps = np.mean([crps_ensemble(y_val[iseed][target_cat][i], y_pred_ensemble[:, i, :].T) \n",
    "                                for i in range(len(y_val[iseed][target_cat]))])\n",
    "                mean_score.append(val_crps)\n",
    "\n",
    "                # Track the best seed for this PC\n",
    "                if val_crps == min(mean_score):  # Check if this seed gives the best RMSE\n",
    "                    current_best_iseed = iseed\n",
    "\n",
    "            # Compute the mean CRPS across seeds\n",
    "            mean_val_crps = np.mean(mean_score)\n",
    "\n",
    "            # Update the best PC if this one performs better\n",
    "            if mean_val_crps < best_mean_val_crps:\n",
    "                best_mean_val_crps = mean_val_crps\n",
    "                best_var = var\n",
    "                best_pc_index = pc_index\n",
    "                best_iseed = current_best_iseed\n",
    "\n",
    "    # Check if we found a PC that improves validation RMSE\n",
    "    if best_var and best_mean_val_crps < best_val_crps:\n",
    "        # Add the best-performing PC to the selected set\n",
    "        selected_pcs.append((best_var, best_pc_index))\n",
    "        remaining_vars.remove(best_var)\n",
    "        best_val_crps = best_mean_val_crps\n",
    "        print(f\"Selected PC: {best_var}_PC{best_pc_index + 1}, Mean Val RMSE: {best_mean_val_crps}, Seed: {best_iseed}\")\n",
    "    else:\n",
    "        print(\"No improvement. Stopping feature selection.\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Climatolopgy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test:6.234292848513657\n",
      "Validation:5.605705404301584\n",
      "Training:5.750965193012404\n"
     ]
    }
   ],
   "source": [
    "meantrain_val = []\n",
    "meantrain_train = []\n",
    "meantrain_test = []\n",
    "for i in range(7):\n",
    "    meantrain_val.append([y_train[i]['max'].mean(axis=0) for _ in range(y_val[i]['cdf'].shape[0])])\n",
    "    meantrain_train.append([y_train[i]['max'].mean(axis=0) for _ in range(y_train[i]['cdf'].shape[0])])\n",
    "    meantrain_test.append([y_train[i]['max'].mean(axis=0) for _ in range(y_testz[i]['cdf'].shape[0])])\n",
    "\n",
    "print(f\"Test:{np.mean(np.asarray([mean_squared_error(y_testz[i]['max'], meantrain_test[i], squared=False) for i in range(7)]))}\")\n",
    "print(f\"Validation:{np.mean(np.asarray([mean_squared_error(y_val[i]['max'], meantrain_val[i], squared=False) for i in range(7)]))}\")\n",
    "print(f\"Training:{np.mean(np.asarray([mean_squared_error(y_train[i]['max'], meantrain_train[i], squared=False) for i in range(7)]))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_bootstrap = 100  # Number of bootstrap iterations\n",
    "n_seeds = 7        # Number of seeds (models)\n",
    "\n",
    "# Collect CRPS scores for each bootstrap iteration\n",
    "bootstrap_crps = []\n",
    "\n",
    "for _ in range(n_bootstrap):\n",
    "    crps_scores = []\n",
    "    \n",
    "    for i in range(n_seeds):\n",
    "        # Resample indices with replacement\n",
    "        n_samples = y_val[i]['max'].shape[0]\n",
    "        resampled_indices = resample(range(n_samples), replace=True, n_samples=n_samples)\n",
    "        \n",
    "        # Resampled validation data and predicted mean\n",
    "        y_val_resampled = y_val[i]['max'][resampled_indices]\n",
    "        mean_pred_resampled = np.array([y_train[i]['max'].mean(axis=0) for _ in resampled_indices])\n",
    "        \n",
    "        # Evaluate CRPS score for the resampled data\n",
    "        crps = np.mean(crps_ensemble(y_val_resampled, mean_pred_resampled))\n",
    "        crps_scores.append(crps)\n",
    "    \n",
    "    # Average CRPS across all seeds for this bootstrap iteration\n",
    "    bootstrap_crps.append(np.mean(crps_scores))\n",
    "\n",
    "# Final CRPS statistics\n",
    "mean_crps = np.mean(bootstrap_crps)\n",
    "std_crps = np.std(bootstrap_crps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.706198990643481"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_crps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 5, 6, 1, 6, 8, 2, 0, 2]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resampled_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [10:45<00:00, 32.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected PC: geopotential_500_max_PC10, Mean Val RMSE: 6.443124888320203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [10:30<00:00, 33.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected PC: 2m_dewpoint_temperature_std_PC2, Mean Val RMSE: 5.921249557472562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [10:12<00:00, 34.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected PC: geopotential_1000_std_PC5, Mean Val RMSE: 5.803620133166346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [09:49<00:00, 34.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected PC: 10m_u_component_of_wind_max_PC5, Mean Val RMSE: 5.771318195730873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [09:25<00:00, 35.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected PC: mean_sea_level_pressure_min_PC9, Mean Val RMSE: 5.699846904096437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [08:55<00:00, 35.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected PC: mean_sea_level_pressure_std_PC10, Mean Val RMSE: 5.637261674504501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [08:41<00:00, 37.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected PC: surface_pressure_max_PC7, Mean Val RMSE: 5.621093085531342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [08:03<00:00, 37.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected PC: geopotential_500_mean_PC5, Mean Val RMSE: 5.616834758396101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [07:31<00:00, 37.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected PC: mean_surface_latent_heat_flux_mean_PC7, Mean Val RMSE: 5.5967161443115305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [06:58<00:00, 38.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected PC: mean_sea_level_pressure_mean_PC6, Mean Val RMSE: 5.569124719086719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [06:27<00:00, 38.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected PC: surface_latent_heat_flux_mean_PC6, Mean Val RMSE: 5.49754599271219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [05:52<00:00, 39.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No improvement. Stopping feature selection.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables\n",
    "selected_pcs = []  # List to store selected PCs\n",
    "remaining_vars = list(pcs_train[0].keys())  # All variables initially available for selection\n",
    "best_val_rmse = float('inf')  # Start with a very high RMSE value\n",
    "\n",
    "while remaining_vars:\n",
    "    best_var = None\n",
    "    best_pc_index = None\n",
    "    best_mean_val_rmse = best_val_rmse\n",
    "\n",
    "    # Test each variable\n",
    "    for var in tqdm(remaining_vars):\n",
    "        nPC = pcs_train[0][var].shape[1]  # Number of PCs for this variable\n",
    "\n",
    "        # Test each PC of the variable\n",
    "        for pc_index in range(nPC):\n",
    "            mean_score = []\n",
    "\n",
    "            # Evaluate using all seeds\n",
    "            for iseed in range(7):\n",
    "                # Prepare data for the current candidate PC\n",
    "                candidate_features = [pcs_train[iseed][sel_var][:, [pc_idx]] \n",
    "                                      for sel_var, pc_idx in selected_pcs]\n",
    "                candidate_features.append(pcs_train[iseed][var][:, [pc_index]])\n",
    "                X_train_subset = np.hstack(candidate_features)\n",
    "                X_val_subset = np.hstack(\n",
    "                    [pcs_val[iseed][sel_var][:, [pc_idx]] for sel_var, pc_idx in selected_pcs] +\n",
    "                    [pcs_val[iseed][var][:, [pc_index]]]\n",
    "                )\n",
    "\n",
    "                # Train a model and evaluate\n",
    "                model = RandomForestRegressor(random_state=seed)\n",
    "                grid_search = GridSearchCV(\n",
    "                    estimator=model,\n",
    "                    param_grid=param_grid,\n",
    "                    scoring=\"neg_root_mean_squared_error\",  # Use RMSE as scoring metric\n",
    "                    cv=3,  # Inner cross-validation\n",
    "                )\n",
    "                grid_search.fit(X_train_subset, y_train[iseed][target_cat])\n",
    "                \n",
    "                # Use the best model to predict\n",
    "                model = grid_search.best_estimator_\n",
    "                #model.fit(X_train_subset, y_train[iseed][target_cat])\n",
    "                y_pred = model.predict(X_val_subset)\n",
    "\n",
    "                # Calculate the validation RMSE\n",
    "                val_rmse = mean_squared_error(y_val[iseed][target_cat], y_pred, squared=False)\n",
    "                mean_score.append(val_rmse)\n",
    "\n",
    "            # Compute the mean validation RMSE across seeds\n",
    "            mean_val_rmse = np.mean(mean_score)\n",
    "\n",
    "            # Update the best PC if this one performs better\n",
    "            if mean_val_rmse < best_mean_val_rmse:\n",
    "                best_mean_val_rmse = mean_val_rmse\n",
    "                best_var = var\n",
    "                best_pc_index = pc_index\n",
    "\n",
    "    # Check if we found a PC that improves validation RMSE\n",
    "    if best_var and best_mean_val_rmse < best_val_rmse:\n",
    "        # Add the best-performing PC to the selected set\n",
    "        selected_pcs.append((best_var, best_pc_index))\n",
    "        remaining_vars.remove(best_var)\n",
    "        best_val_rmse = best_mean_val_rmse\n",
    "        print(f\"Selected PC: {best_var}_PC{best_pc_index + 1}, Mean Val RMSE: {best_mean_val_rmse}\")\n",
    "    else:\n",
    "        print(\"No improvement. Stopping feature selection.\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### probabilistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected PC: geopotential_500_max_PC10, Mean Val CRPS: 4.404707118874361\n",
      "Selected PC: geopotential_500_mean_PC9, Mean Val CRPS: 3.729450611336759\n",
      "Selected PC: surface_pressure_mean_PC11, Mean Val CRPS: 3.5516674759429776\n",
      "Selected PC: geopotential_1000_std_PC10, Mean Val CRPS: 3.4916252511325006\n",
      "Selected PC: 2m_dewpoint_temperature_std_PC10, Mean Val CRPS: 3.430094883373766\n",
      "Selected PC: surface_latent_heat_flux_min_PC4, Mean Val CRPS: 3.394558978769711\n",
      "Selected PC: 10m_u_component_of_wind_max_PC2, Mean Val CRPS: 3.3793392212730993\n",
      "Selected PC: mean_sea_level_pressure_min_PC9, Mean Val CRPS: 3.338790111026809\n",
      "Selected PC: surface_pressure_max_PC8, Mean Val CRPS: 3.3204019809062046\n",
      "Selected PC: mean_sea_level_pressure_std_PC10, Mean Val CRPS: 3.2840720501433087\n",
      "Selected PC: 10m_v_component_of_wind_max_PC2, Mean Val CRPS: 3.28273212527452\n",
      "Selected PC: geopotential_1000_min_PC5, Mean Val CRPS: 3.2644896778478953\n",
      "Selected PC: mean_surface_latent_heat_flux_min_PC4, Mean Val CRPS: 3.2580280566965847\n",
      "Selected PC: mean_sea_level_pressure_max_PC7, Mean Val CRPS: 3.242935931193398\n",
      "No improvement. Stopping feature selection.\n"
     ]
    }
   ],
   "source": [
    "from properscoring import crps_ensemble  # For CRPS calculation\n",
    "import numpy as np\n",
    "\n",
    "# Initialize variables\n",
    "selected_pcs = []  # List to store selected PCs as (variable, pc_index) tuples\n",
    "remaining_vars = list(pcs_train[0].keys())  # Variables initially available for selection\n",
    "best_val_crps = float('inf')  # Start with a very high CRPS value\n",
    "\n",
    "while remaining_vars:\n",
    "    best_var = None\n",
    "    best_pc_index = None\n",
    "    best_mean_val_crps = best_val_crps\n",
    "\n",
    "    # Test each variable\n",
    "    for var in remaining_vars:\n",
    "        nPC = pcs_train[0][var].shape[1]  # Number of PCs for this variable\n",
    "\n",
    "        # Test each PC of the variable\n",
    "        for pc_index in range(nPC):\n",
    "            mean_score = []\n",
    "\n",
    "            # Evaluate using all seeds\n",
    "            for iseed in range(7):\n",
    "                # Prepare data for the current candidate PC\n",
    "                candidate_features = [pcs_train[iseed][sel_var][:, [pc_idx]] \n",
    "                                      for sel_var, pc_idx in selected_pcs]\n",
    "                candidate_features.append(pcs_train[iseed][var][:, [pc_index]])\n",
    "                X_train_subset = np.hstack(candidate_features)\n",
    "                X_val_subset = np.hstack(\n",
    "                    [pcs_val[iseed][sel_var][:, [pc_idx]] for sel_var, pc_idx in selected_pcs] +\n",
    "                    [pcs_val[iseed][var][:, [pc_index]]]\n",
    "                )\n",
    "\n",
    "                # Train a probabilistic model\n",
    "                model = RandomForestRegressor(n_estimators=100, random_state=seed)\n",
    "                model.fit(X_train_subset, y_train[iseed][target_cat])\n",
    "                # Use the best model to predict\n",
    "                y_pred_ensemble = np.array([tree.predict(X_val_subset) for tree in model.estimators_])\n",
    "\n",
    "                # Calculate the CRPS score\n",
    "                crps = np.mean([crps_ensemble(y_val[iseed][target_cat][i], y_pred_ensemble[:, i, :].T) \n",
    "                                for i in range(len(y_val[iseed][target_cat]))])\n",
    "                mean_score.append(crps)\n",
    "\n",
    "            # Compute the mean CRPS across seeds\n",
    "            mean_val_crps = np.mean(mean_score)\n",
    "\n",
    "            # Update the best PC if this one performs better\n",
    "            if mean_val_crps < best_mean_val_crps:\n",
    "                best_mean_val_crps = mean_val_crps\n",
    "                best_var = var\n",
    "                best_pc_index = pc_index\n",
    "\n",
    "    # Check if we found a PC that improves validation CRPS\n",
    "    if best_var and best_mean_val_crps < best_val_crps:\n",
    "        # Add the best-performing PC to the selected set\n",
    "        selected_pcs.append((best_var, best_pc_index))\n",
    "        remaining_vars.remove(best_var)  # Remove the variable from remaining_vars\n",
    "        best_val_crps = best_mean_val_crps\n",
    "        print(f\"Selected PC: {best_var}_PC{best_pc_index + 1}, Mean Val CRPS: {best_mean_val_crps}\")\n",
    "    else:\n",
    "        print(\"No improvement. Stopping feature selection.\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
